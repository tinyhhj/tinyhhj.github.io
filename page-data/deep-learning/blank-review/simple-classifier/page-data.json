{"componentChunkName":"component---src-templates-blog-post-js","path":"/deep-learning/blank-review/simple-classifier/","result":{"data":{"site":{"id":"Site","siteMetadata":{"title":"Gatsby Starter Blog"}},"markdownRemark":{"id":"3b86b2ec-987e-58ae-b460-4b5ee1e54254","excerpt":"Simple-classifier 문제 fashion mnist 구분하기 reference 펭귄브로의 3분 딥러닝, 파이토치맛","html":"<h2>Simple-classifier</h2>\n<h3>문제</h3>\n<ol>\n<li>fashion mnist 구분하기</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets\nimport math\n\n\ntrain = datasets.FashionMNIST(&#39;fashion_mnist&#39;,transform=transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))\n]),train=True,download=True)\ntrain2 = datasets.FashionMNIST(&#39;fashion_mnist&#39;,transform=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))\n]),train=True)\ntest = datasets.FashionMNIST(&#39;fashion_mnist&#39;, transform=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))\n]), train=False, download=True)\n\nbs = 64\ntrain_loader = torch.utils.data.DataLoader(train,\n                            batch_size=bs,\n                            )\ntrain2_loader = torch.utils.data.DataLoader(train2,batch_size=bs)\n\ntest_loader = torch.utils.data.DataLoader(test, batch_size=bs, shuffle = True)\n\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\ndataiter2 = iter(train2_loader)\nimages2, _ = next(dataiter2)\nimages2 = torch.cat([images2,images2,images2],1)\n\nimg = torchvision.utils.make_grid(images, padding = 0)\nrow = []\nfor r in range(0,len(images2),8):\n    row.append(torch.cat([*images2[r:r+8]],2))\nimg2 = torch.cat(row,1)\n\n\nnpimg = img.numpy()\nnpimg2 = img2.numpy()\nprint(npimg.shape, npimg2.shape)\nplt.figure(figsize=(10,7))\nplt.imshow(np.transpose(npimg,(1,2,0)))\nplt.figure(2,figsize=(10,7))\nplt.imshow(np.transpose(npimg2,(1,2,0)))\n# plt.show()\n\n# exit()\n\nclass Net(nn.Module):\n    def __init__(self,dropout_p = 0.2):\n        super(Net,self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(28*28, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_p),\n            nn.Linear(256,128),\n            nn.ReLU(),\n            nn.Dropout(dropout_p),\n            nn.Linear(128,10)\n        )\n\n    def forward(self, images):\n        images = images.view(-1,784)\n        return self.net(images)\n\ndevice = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)\n\nepochs = 50\nsize = 64\n\nnet = Net().to(device)\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\ndef train(model, loader, optimizer):\n    model.train()\n    for i, (images, labels) in enumerate(loader):\n        data , target = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        pred = model(data)\n\n        loss = F.cross_entropy(pred, target)\n        loss.backward()\n        optimizer.step()\n\ndef evaluate(model, loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for data, target in loader:\n            data, target = data.to(device), target.to(device)\n            pred = model(data)\n            # print(&#39;input:{},output:{}&#39;.format(data.size(), pred.size()))\n            loss = F.cross_entropy(pred, target,reduction=&#39;sum&#39;).item()\n            test_loss += loss\n            pred = pred.max(1,keepdim=True)[1]\n\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            # print(&#39;pred:{},target:{}&#39;.format(pred.size(),target.view_as(pred).size()))\n        test_loss /= len(loader.dataset)\n        test_accuracy = 100. * correct / len(loader.dataset)\n        return test_loss, test_accuracy\n\n\nfor e in range(epochs):\n    train(net,train_loader,optimizer)\n    test_loss, test_accuracy = evaluate(net, test_loader)\n    print(&#39;test loss:{} , test_accuracy:{}&#39;.format(test_loss, test_accuracy))</code></pre></div>\n<h3>reference</h3>\n<ul>\n<li><a href=\"http://www.hanbit.co.kr/store/books/look.php?p_code=B7193109877\">펭귄브로의 3분 딥러닝, 파이토치맛</a></li>\n</ul>","frontmatter":{"title":"[deeplearning]simple-classifier","date":"February 23, 2020","description":"deep-learning"}}},"pageContext":{"slug":"/deep-learning/blank-review/simple-classifier/","previous":{"fields":{"slug":"/deep-learning/batchnorm/"},"frontmatter":{"title":"[deeplearning]batchnorm"}},"next":{"fields":{"slug":"/deep-learning-from-scratch/index4/"},"frontmatter":{"title":""}}}}}
{"componentChunkName":"component---src-templates-blog-post-js","path":"/deep-learning-from-scratch/index2/","result":{"data":{"site":{"id":"Site","siteMetadata":{"title":"Gatsby Starter Blog"}},"markdownRemark":{"id":"d6448b04-ea8e-59da-b592-ecd94d7dd73b","excerpt":"deep-learning-from-scratch chap 2","html":"<h2><a href=\"https://github.com/WegraLee/deep-learning-from-scratch\">deep-learning-from-scratch</a></h2>\n<h3>chap 2</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&#39;&#39;&#39;\n# perceptron\n# input : 여러 신호( 전류나 강물처럼 흐름이 있는..)\n# output: 1 or 0 (1: 신호가 흐른다, 0 : 흐르지 않는다)\n# 임계값(theta): 입력신호마다(x1,x2,..xn) 가중치(w1,w2,..wn)을 곱해 임계치를 넘을경우 출력신호(1)을 내보낸다.\n# 가중치는 각 신호가 결과에 주는 영향력을 나타내는 요소( 즉 가중치가 클수록 중요한 신호임을 뜻합니다.)\n\nx1*w1 + x2*w2 + .. xn*wn &lt;= theta (return 0)\nx1*w1 + x2*w2 + .. xn*wn &gt; theta (return 1)\n\n\n논리회로 and 게이트\nx1 x2 y\n0  0  0\n0  1  0\n1  0  0\n1  1  1\n\n퍼셉트론을 이용해 논리 and게이트를 만들 때 w1,w2(각 입력의 가중치)와 임계값(theta)를 정해야 합니다.\n  w1  w2  theta\n(0.5,0.5,0.7)\n(0.5,0.5,0.8)\n...\nand 게이트의 조건을 만족하는 매개변수 조합은 무수히 많습니다.\n\nnand 게이트\nx1 x2 y\n0  0  1\n0  1  1\n1  0  1\n1  1  0\nand 게이트 조건을 만족하는 매개변수들의 부호를 변경하면 모두 만족합니다.\n\n위와 같은 문제일 경우 문제를 해결하는 방식을 생각해보면\nand 게이트의 진리표라는 &#39;학습데이터&#39;를 보면서 알맞은 매개변수의 값을 찾습니다.\n기계학습 문제는 이 매개변수의 값을 컴퓨터가 자동으로 찾도록 하는것을 말합니다.\n학습이란 적절한 매개변수 값을 정하는 행위이며, 사람은 퍼셉트론의 구조(모델)을 고민하고\n컴퓨터에 학습할 데이터를 주는 역할을 합니다.\n\nand , nand ,or 게이트 모두 같은 구조의 퍼셉트론이 역할을 수행할 수 있고, 각 게이트마다 다른점은 매개변수(가중치와 임계값)일 뿐입니다.\n즉 매개변수에 따라서 다양하게 역할을 수행하도록 퍼셉트론을 변경할 수 있습니다.\n&#39;&#39;&#39;\n\n# and gate\n\ndef AND(x1,x2):\n    w1,w2,theta = 0.5,0.5,0.7\n    if x1*w1+x2*w2 &lt;= theta:\n        return 0\n    else:\n        return 1\nprint(AND(0,0))\nprint(AND(0,1))\nprint(AND(1,0))\nprint(AND(1,1))\n\n&#39;&#39;&#39;\ntheta = -b\nb를 편향이라고 부르며\nx1*w1 + x2*w2 + .. xn*wn &lt;= -b (return 0)\nx1*w1 + x2*w2 + .. xn*wn &gt; -b (return 1)\n위 수식을\nb +  x1*w1 + x2*w2 + .. xn*wn &lt;= 0 (return 0)\nb +  x1*w1 + x2*w2 + .. xn*wn &gt; 0 (return 1)\n로 변경이 가능합니다.\n\n편향과 가중치와 차이점에 주의합니다\n가중치: 각 입력신호가 결과에 주는 영향력(중요도)를 조절하는 매개변수\n편향: 뉴런이 얼마나 쉽게 활성화 하느냐 조절하는 매개변수\n&#39;&#39;&#39;\nimport numpy as np\nx = np.array([0,1])\nw = np.array([0.5,0.5])\nb = -0.7\n\nprint(np.sum(w*x)+ b)\n\ndef And(x1,x2):\n    w = np.array([0.5,0.5])\n    b = -0.7\n    x = np.array([x1,x2])\n    tmp = np.sum(w*x)+b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\n\ndef Or(x1,x2):\n    w = np.array([0.5,0.5])\n    b = -0.1\n    x = np.array([x1,x2])\n    tmp = np.sum(w*x)+ b\n    if tmp &lt;= 0:\n        return 0\n    else:\n        return 1\ndef Nand(x1,x2):\n    if And(x1,x2) &lt;= 0:\n        return 1\n    else:\n        return 0\n\n\n\n&#39;&#39;&#39;\n퍼셉트론의 한계 \n직선으로만 출력이 표현가능하기 때문에 xor같은 비선형 데이터를 표현할 수 없습니다.\n퍼셉트론을 여러 층으로 쌓으면 xor와 같은 비선형 데이터를 표현할 수 있습니다.\n\n&#39;&#39;&#39;\ndef Xor(x1,x2):\n    s1 = Nand(x1,x2)\n    s2 = Or(x1,x2)\n    return And(s1,s2)\n\nprint(Xor(0,0))\nprint(Xor(0,1))\nprint(Xor(1,0))\nprint(Xor(1,1))</code></pre></div>","frontmatter":{"title":"[python]deep-learning-2","date":"January 28, 2020","description":"deep-learning"}}},"pageContext":{"slug":"/deep-learning-from-scratch/index2/","previous":{"fields":{"slug":"/deep-learning-from-scratch/index3/"},"frontmatter":{"title":"[python]deep-learning-3"}},"next":{"fields":{"slug":"/deep-learning-from-scratch/index1/"},"frontmatter":{"title":"[python]deep-learning-1"}}}}}